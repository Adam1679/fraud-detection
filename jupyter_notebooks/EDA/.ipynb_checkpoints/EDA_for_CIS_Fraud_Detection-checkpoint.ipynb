{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel I will do my EDA on the dataset, make some visualizations, try to find any insights and create some new features.\n",
    "\n",
    "Join me, it promises to be a thrilling adventure.\n",
    "\n",
    "Some tricks being used:\n",
    "* [card1 count encoding](#1)\n",
    "* [Covariate Shift](#2)\n",
    "* [features interaction](#3)\n",
    "* [data relaxation](#4)\n",
    "\n",
    "New engineered features:\n",
    "* [Number of NaNs](#5)\n",
    "* [TransactionAmt and it's decimal part](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all datasets using multiprocessing. This speads up a process a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../../ieee-fraud-detection\"\n",
    "files = [f'{DIR}/test_identity.csv', \n",
    "         f'{DIR}/test_transaction.csv',\n",
    "         f'{DIR}/train_identity.csv',\n",
    "         f'{DIR}/train_transaction.csv',\n",
    "         f'{DIR}/sample_submission.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 8.88 s, total: 12.6 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f9ea213d9bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TransactionID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TransactionID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tr' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n",
    "\n",
    "del test_id, test_tr, train_id, train_tr\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def plot_numerical(feature):\n",
    "    \"\"\"\n",
    "    Plot some information about a numerical feature for both train and test set.\n",
    "    Args:\n",
    "        feature (str): name of the column in DataFrame\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16, 18))\n",
    "    sns.kdeplot(train[feature], ax=axes[0][0], label='Train');\n",
    "    sns.kdeplot(test[feature], ax=axes[0][0], label='Test');\n",
    "\n",
    "    sns.kdeplot(train[train['isFraud']==0][feature], ax=axes[0][1], label='isFraud 0')\n",
    "    sns.kdeplot(train[train['isFraud']==1][feature], ax=axes[0][1], label='isFraud 1')\n",
    "\n",
    "    test[feature].index += len(train)\n",
    "    axes[1][0].plot(train[feature], '.', label='Train');\n",
    "    axes[1][0].plot(test[feature], '.', label='Test');\n",
    "    axes[1][0].set_xlabel('row index');\n",
    "    axes[1][0].legend()\n",
    "    test[feature].index -= len(train)\n",
    "\n",
    "    axes[1][1].plot(train[train['isFraud']==0][feature], '.', label='isFraud 0');\n",
    "    axes[1][1].plot(train[train['isFraud']==1][feature], '.', label='isFraud 1');\n",
    "    axes[1][1].set_xlabel('row index');\n",
    "    axes[1][1].legend()\n",
    "\n",
    "    pd.DataFrame({'train': [train[feature].isnull().sum()], 'test': [test[feature].isnull().sum()]}).plot(kind='bar', rot=0, ax=axes[2][0]);\n",
    "    pd.DataFrame({'isFraud 0': [train[(train['isFraud']==0) & (train[feature].isnull())][feature].shape[0]],\n",
    "                  'isFraud 1': [train[(train['isFraud']==1) & (train[feature].isnull())][feature].shape[0]]}).plot(kind='bar', rot=0, ax=axes[2][1]);\n",
    "\n",
    "    fig.suptitle(feature, fontsize=18);\n",
    "    axes[0][0].set_title('Train/Test KDE distribution');\n",
    "    axes[0][1].set_title('Target value KDE distribution');\n",
    "    axes[1][0].set_title('Index versus value: Train/Test distribution');\n",
    "    axes[1][1].set_title('Index versus value: Target distribution');\n",
    "    axes[2][0].set_title('Number of NaNs');\n",
    "    axes[2][1].set_title('Target value distribution among NaN values');\n",
    "    \n",
    "# This code is stolen from Chris Deotte. \n",
    "def relax_data(df_train, df_test, col):\n",
    "    cv1 = pd.DataFrame(df_train[col].value_counts().reset_index().rename({col:'train'},axis=1))\n",
    "    cv2 = pd.DataFrame(df_test[col].value_counts().reset_index().rename({col:'test'},axis=1))\n",
    "    cv3 = pd.merge(cv1,cv2,on='index',how='outer')\n",
    "    factor = len(df_test)/len(df_train)\n",
    "    cv3['train'].fillna(0,inplace=True)\n",
    "    cv3['test'].fillna(0,inplace=True)\n",
    "    cv3['remove'] = False\n",
    "    cv3['remove'] = cv3['remove'] | (cv3['train'] < len(df_train)/10000)\n",
    "    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] < cv3['test']/3)\n",
    "    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] > 3*cv3['test'])\n",
    "    cv3['new'] = cv3.apply(lambda x: x['index'] if x['remove']==False else 0,axis=1)\n",
    "    cv3['new'],_ = cv3['new'].factorize(sort=True)\n",
    "    cv3.set_index('index',inplace=True)\n",
    "    cc = cv3['new'].to_dict()\n",
    "    df_train[col] = df_train[col].map(cc)\n",
    "    df_test[col] = df_test[col].map(cc)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction DT\n",
    "According to the official description 'TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).' I see people in some kernels assume that a start date is a 1 of December 2017, but to be honest the exact start date is not that important. \n",
    "\n",
    "So lets transform TransactionDT into a datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = datetime.datetime.strptime('2017-12-01', '%Y-%m-%d')\n",
    "train['TransactionDT'] = train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "test['TransactionDT'] = test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=axes).set_ylabel('isFraud mean', fontsize=14);\n",
    "axes.set_title('Mean of isFraud by day', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 6))\n",
    "train['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes).set_xlabel('Date', fontsize=14);\n",
    "test['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes).set_ylabel('Number of training examples', fontsize=14);\n",
    "axes.set_title('Number of training examples by day', fontsize=16);\n",
    "axes.legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now combining both mean of isFraud by day and number of training examples by day into a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_ylabel('isFraud mean', color='blue', fontsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "train['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=ax2, color='tab:orange');\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange');\n",
    "ax2.set_ylabel('Number of training examples', color='tab:orange', fontsize=14);\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# card1\n",
    "I have decided to start from one of the most important features of this dataset according to LightGBM feature_importance. And **card1** is one of those features.\n",
    "\n",
    "What I did is I've created a separate dataset with only this feature in it and also I added one more feature to this new dataset, which is an original feature's frequency (count) encoding. Why I did this? Well, you can reference [Santander Customer Transaction Prediction](https://www.kaggle.com/c/santander-customer-transaction-prediction) competition, where this kind of encoding really boosted a score up. \n",
    "\n",
    "I'll make some visualizations (shoutout to [Chris Deotte](https://www.kaggle.com/cdeotte)) to show you why that works and might work in this case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "X = pd.DataFrame()\n",
    "X['card1'] = train['card1']\n",
    "X['card1_count'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = DecisionTreeClassifier(max_leaf_nodes=4)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we train a simple decision tree, using this two features we have an AUC slightly higher that 0.5. Let's see why by plotting this tree as a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "tree_graph = tree.export_graphviz(clf, out_file=None, max_depth = 10,\n",
    "    impurity = False, feature_names = X.columns, class_names = ['0', '1'],\n",
    "    rounded = True, filled= True )\n",
    "graphviz.Source(tree_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first split is by the values less than or equal to 10881.5 (black line) and the second one is 8750.0 (red line) and a tree does not use a count feature at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.kdeplot(X[y==1]['card1'], label='isFraud 1');\n",
    "sns.kdeplot(X[y==0]['card1'], label='isFraud 0');\n",
    "plt.plot([10881.5, 10881.5], [0.0000, 0.0001], sns.xkcd_rgb[\"black\"], lw=2);\n",
    "plt.plot([8750.0, 8750.0], [0.0000, 0.0001], sns.xkcd_rgb[\"red\"], lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But lets take a little step back and train a boosting model on only one original feature card1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary', \"boosting_type\": \"gbdt\", \"subsample\": 1, \"bagging_seed\": 11, \"metric\": 'auc', 'random_state': 47}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['card1'], y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "print('ROC AUC score', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a heatmap with a probability of isFraud=1 for every unique value in the **card1** feature.\n",
    "\n",
    "This picture reminds me an opening from a Total Recall movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "x = clf.predict_proba(X['card1'].sort_values().unique().reshape(-1, 1))[:, 1]\n",
    "x = pd.Series(x, index=X['card1'].sort_values().unique())\n",
    "sns.heatmap(x.to_frame(), cmap='RdBu_r', center=0.0);\n",
    "plt.xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add a second feature - count encoded **card1** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout score has significantly increased. Lets create another heatmap and see why. \n",
    "\n",
    "There are some darker spots in some intersections of the variable **card1** values and it's count encoded values. This is the reason of the holdout score improvement.\n",
    "\n",
    "*The image is pre-rendered since rendering takes some significant amount of time*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1696976%2F7153f1242daa586d6849c83242c3fe40%2F35267aee89a7552caf082b6bb0039aa5-full.png?generation=1564585074348507&alt=media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('card1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting this variable gives us such information as:\n",
    "* distribution in train and test set is almost equal.\n",
    "* distribution between target values differs, which make this feature so valuable\n",
    "* this feature doesn't have any NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "Lets check a Covariate Shift of the feature. This means that we will try to distinguish whether a values correspond to a training set or to a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def covariate_shift(feature):\n",
    "    df_card1_train = pd.DataFrame(data={feature: train[feature], 'isTest': 0})\n",
    "    df_card1_test = pd.DataFrame(data={feature: test[feature], 'isTest': 1})\n",
    "\n",
    "    # Creating a single dataframe\n",
    "    df = pd.concat([df_card1_train, df_card1_test], ignore_index=True)\n",
    "    \n",
    "    # Encoding if feature is categorical\n",
    "    if str(df[feature].dtype) in ['object', 'category']:\n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature].astype(str))\n",
    "    \n",
    "    # Splitting it to a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[feature], df['isTest'], test_size=0.33, random_state=47, stratify=df['isTest'])\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**params, num_boost_round=500)\n",
    "    clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "    roc_auc =  roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1])\n",
    "\n",
    "    del df, X_train, y_train, X_test, y_test\n",
    "    gc.collect();\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate Shift ROC AUC score:', covariate_shift('card1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC score is close to 0.5, this means that this feature almost does not have any shift between train and test and is definitely worth keeping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProductCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data={'ProductCD': train['ProductCD'], 'isTest': 0})\n",
    "df_test = pd.DataFrame(data={'ProductCD': test['ProductCD'], 'isTest': 1})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.countplot(data=df.fillna('NaN'), x='ProductCD', hue='isTest', ax=axes[0]);\n",
    "sns.countplot(data=train[['ProductCD', 'isFraud']].fillna('NaN'), x='ProductCD', hue='isFraud', ax=axes[1]);\n",
    "axes[0].set_title('Train / Test distibution');\n",
    "axes[1].set_title('Train distibution by isFraud');\n",
    "axes[0].legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('ProductCD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a count feature for card2 to perform the same experiment as with card1. First the heatmap for all possible interactions of card2 feature and it's count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "X = pd.DataFrame()\n",
    "X['card2'] = train['card2']\n",
    "X['card2_count'] = train['card2'].map(pd.concat([train['card2'], test['card2']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for i in X['card2'].sort_values().unique():\n",
    "    x = pd.DataFrame()\n",
    "    x['card2'] = [i] * X['card2_count'].nunique()\n",
    "    x['card2_count'] = X['card2_count'].sort_values().unique()\n",
    "    \n",
    "    result_df = pd.concat([result_df, x], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "preds = clf.predict_proba(result_df)[:, 1]\n",
    "preds = preds.reshape(X['card2'].nunique(dropna=False), X['card2_count'].nunique(dropna=False))\n",
    "preds = pd.DataFrame(preds, index=X['card2'].sort_values().unique(), columns=X['card2_count'].sort_values().unique())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "sns.heatmap(preds, cmap='RdBu_r', center=0.0);\n",
    "ax.set_ylabel('card2');\n",
    "ax.set_xlabel('card2_count');\n",
    "ax.set_title('card2 / card2_count interaction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a scatter plot with a \"decision boundary\" of the model. White 'X' marks represents a test set examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test_X = pd.DataFrame()\n",
    "test_X['card2'] = test['card2']\n",
    "test_X['card2_count'] = test['card2'].map(pd.concat([train['card2'], test['card2']], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes()\n",
    "sc = plt.scatter(y=result_df['card2'], x=result_df['card2_count'], c=clf.predict_proba(result_df)[:, 1], cmap='RdBu_r');\n",
    "ax.set_ylabel('card2');\n",
    "ax.set_xlabel('card2_count');\n",
    "ax.set_title('card2 / card2_count interaction');\n",
    "plt.colorbar(sc);\n",
    "plt.scatter(y=test_X['card2'], x=test_X['card2_count'], marker='x', c='white', alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('card2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('card2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('card3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('card3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data={'card4': train['card4'], 'isTest': 0})\n",
    "df_test = pd.DataFrame(data={'card4': test['card4'], 'isTest': 1})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.countplot(data=df.fillna('NaN'), x='card4', hue='isTest', ax=axes[0]);\n",
    "sns.countplot(data=train[['card4', 'isFraud']].fillna('NaN'), x='card4', hue='isFraud', ax=axes[1]);\n",
    "axes[0].set_title('Train / Test distibution');\n",
    "axes[1].set_title('Train distibution by isFraud');\n",
    "axes[0].legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('card4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('card5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('card5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# card6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data={'card6': train['card6'], 'isTest': 0})\n",
    "df_test = pd.DataFrame(data={'card6': test['card6'], 'isTest': 1})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.countplot(data=df.fillna('NaN'), x='card6', hue='isTest', ax=axes[0]);\n",
    "sns.countplot(data=train[['card6', 'isFraud']].fillna('NaN'), x='card6', hue='isFraud', ax=axes[1]);\n",
    "axes[0].set_title('Train / Test distibution');\n",
    "axes[1].set_title('Train distibution by isFraud');\n",
    "axes[0].legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC:', covariate_shift('card6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# addr1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature with a relatively high importance is **addr1**. According to the name of the feature we can assume that it contains some kind of users address, but in an encoded way. Also this time a feature have some missing values. We are going to fill them with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "X = pd.DataFrame()\n",
    "X['addr1'] = train['addr1']\n",
    "X['addr1_count'] = train['addr1'].map(pd.concat([train['addr1'], test['addr1']], ignore_index=True).value_counts(dropna=False))\n",
    "X['addr1'].fillna(0, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['addr1'], y, test_size=0.33, random_state=47)\n",
    "clf = DecisionTreeClassifier(max_leaf_nodes=4)\n",
    "clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "tree_graph = tree.export_graphviz(clf, out_file=None, max_depth = 10,\n",
    "    impurity = False, feature_names = ['addr1'], class_names = ['0', '1'],\n",
    "    rounded = True, filled= True )\n",
    "graphviz.Source(tree_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.kdeplot(X[y==1]['addr1'], label='isFraud 1');\n",
    "sns.kdeplot(X[y==0]['addr1'], label='isFraud 0');\n",
    "plt.plot([50.0, 50.0], [0.0000, 0.008], sns.xkcd_rgb[\"black\"], lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again training a gradient boosting model with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'binary', \"boosting_type\": \"gbdt\", \"subsample\": 1, \"bagging_seed\": 11, \"metric\": 'auc', 'random_state': 47}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['addr1'], y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "x = clf.predict_proba(X['addr1'].sort_values().unique().reshape(-1, 1))[:, 1]\n",
    "x = pd.Series(x, index=X['addr1'].sort_values().unique())\n",
    "sns.heatmap(x.to_frame(), cmap='RdBu_r', center=0.0);\n",
    "plt.xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we are doing exactly the same thing that we have been doing for the previous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "for i in X['addr1'].sort_values().unique():\n",
    "    x = pd.DataFrame()\n",
    "    x['addr1'] = [i] * X['addr1_count'].nunique()\n",
    "    x['addr1_count'] = X['addr1_count'].sort_values().unique()\n",
    "    \n",
    "    result_df = pd.concat([result_df, x], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(result_df)[:, 1]\n",
    "preds = preds.reshape(X['addr1'].nunique(), X['addr1_count'].nunique())\n",
    "preds = pd.DataFrame(preds, index=X['addr1'].sort_values().unique(), columns=X['addr1_count'].sort_values().unique())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(preds, cmap='RdBu_r', center=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('addr1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution is the same, amount of NaN's is the same. Some difference in target value distribution. \n",
    "\n",
    "Next checking Covariate Shift for addr1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift ROC AUC score:', covariate_shift('addr1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC score is close to 0.5\n",
    "\n",
    "This feature also does not have any shift between train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# card1 to addr1 interaction\n",
    "\n",
    "Next I am going to create a new feature out of this two features interaction and train on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "X['addr1'] = train['addr1']\n",
    "X['card1'] = train['card1']\n",
    "y = train['isFraud']\n",
    "X['addr1'].fillna(0, inplace=True)\n",
    "\n",
    "X['addr1_card1'] = X['addr1'].astype(str) + '_' + X['card1'].astype(str)\n",
    "X['addr1_card1'] = LabelEncoder().fit_transform(X['addr1_card1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First training a model only using this two features, without their interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['addr1', 'card1']], y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now WITH interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['addr1', 'card1', 'addr1_card1']], y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf1 = lgb.LGBMClassifier(**params)\n",
    "clf1.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf1.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm_notebook(X['addr1'].sort_values().unique()):\n",
    "    x = pd.DataFrame()\n",
    "    x['addr1'] = [i] * X['card1'].nunique()\n",
    "    x['card1'] = X['card1'].sort_values().unique()\n",
    "    \n",
    "    result_df = pd.concat([result_df, x], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions heatmap of the two features interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(result_df)[:, 1]\n",
    "preds = preds.reshape(X['addr1'].nunique(), X['card1'].nunique())\n",
    "preds = pd.DataFrame(preds, index=X['addr1'].sort_values().unique(), columns=X['card1'].sort_values().unique())\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(preds, cmap='RdBu_r', center=0.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally adding count features, so all in all we have 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X['card1_count'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "X['addr1_count'] = train['addr1'].map(pd.concat([train['addr1'], test['addr1']], ignore_index=True).value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# New feature: number of NaN's\n",
    "We have plenty of NaN's in this dataset and they can have a significant effect so why don't we use them?\n",
    "I am adding a new column to the dateset, which will contain a number of NaN for each row. So if a row (a single training example) contain, say, 10 NaNs, a new feature's value for this row will be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nulls'] = train.isnull().sum(axis=1)\n",
    "test['nulls'] = test.isnull().sum(axis=1)\n",
    "plot_numerical('nulls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariant shift ROC AUC:', covariate_shift('nulls'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this feature might be useful, but also keep in mind that covatiate shift is almost 0.7, which tells us that the distribution between train and test set has some difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# TransactionAmt and it's decimal part\n",
    "\n",
    "First let's take a look at TransactionAmt feature and them I will create a new one - it's decimal part, which is a very popular way of creating a new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('TransactionAmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving average for TransactionAmt over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1,figsize=(16, 6))\n",
    "axes.set_title('Moving average of TransactionAmt', fontsize=16);\n",
    "train[['TransactionDT', 'TransactionAmt']].set_index('TransactionDT').rolling(10000).mean().plot(ax=axes);\n",
    "test[['TransactionDT', 'TransactionAmt']].set_index('TransactionDT').rolling(10000).mean().plot(ax=axes);\n",
    "axes.legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=axes).set_ylabel('TransactionAmt mean', fontsize=14);\n",
    "test.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=axes).set_ylabel('TransactionAmt mean', fontsize=14);\n",
    "axes.set_title('Mean of TransactionAmt by day', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relationship between mean of TransactionAmt by day and a mean of isFraud by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_ylabel('isFraud mean by day', color='blue', fontsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "train.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=ax2, color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange');\n",
    "ax2.set_ylabel('TransactionAmt mean by day', color='tab:orange', fontsize=14);\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimal part of transaction amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "plot_numerical('TransactionAmt_decimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=axes).set_ylabel('TransactionAmt_decimal mean', fontsize=14);\n",
    "test.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=axes).set_ylabel('TransactionAmt_decimal mean', fontsize=14);\n",
    "axes.set_title('Mean of TransactionAmt_decimal by day', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relationship between mean of TransactionAmt_decimal by day and a mean of isFraud by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "train.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_ylabel('isFraud mean by day', color='blue', fontsize=14)\n",
    "ax2 = ax1.twinx()\n",
    "train.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=ax2, color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange');\n",
    "ax2.set_ylabel('TransactionAmt_decimal mean by day', color='tab:orange', fontsize=14);\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenght of the decimal part of transaction amount. What does it mean? Well, if lenght is 1 or 2 signs it is totaly understandable - there might be cents. But what is wrong with a decimal part's lenght being 3 and more sings? Maybe it is due to a currency convertion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_decimal_lenght'] = train['TransactionAmt'].astype(str).str.split('.', expand=True)[1].str.len()\n",
    "test['TransactionAmt_decimal_lenght'] = test['TransactionAmt'].astype(str).str.split('.', expand=True)[1].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data={'TransactionAmt_decimal_lenght': train['TransactionAmt_decimal_lenght'], 'isTest': 0})\n",
    "df_test = pd.DataFrame(data={'TransactionAmt_decimal_lenght': test['TransactionAmt_decimal_lenght'], 'isTest': 1})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.countplot(data=df.fillna('NaN'), x='TransactionAmt_decimal_lenght', hue='isTest', ax=axes[0]);\n",
    "sns.countplot(data=train[['TransactionAmt_decimal_lenght', 'isFraud']].fillna('NaN'), x='TransactionAmt_decimal_lenght', hue='isFraud', ax=axes[1]);\n",
    "axes[0].set_title('Train / Test distibution');\n",
    "axes[1].set_title('Train distibution by isFraud');\n",
    "axes[0].legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariate shift for all 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt_decimal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt_decimal_lenght'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V258')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V258'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "This is where I want to introduce a little trick to you, called data relaxation. So what is it? In order to understand it take a look at the plot above. See the distibution difference between train and test set at a certain point? Gradient boosting algorithm doesn't know what to do with a data it has never seen so it will not approximate it well. And what we do by relaxing data is we are removing all the values from the train set that appears in it 3 times more often than in a test set and vice versa, also cleaning all the data that appears in train and test set only couple of times.\n",
    "\n",
    "## V258 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'V258')\n",
    "plot_numerical('V258')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('V294')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('V294'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V294 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'V294')\n",
    "plot_numerical('V294')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C1')\n",
    "plot_numerical('C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('C2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2 after data relaxation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C2')\n",
    "plot_numerical('C2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plot_numerical('C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C3')\n",
    "plot_numerical('C3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C4')\n",
    "plot_numerical('C4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C5 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C5')\n",
    "plot_numerical('C5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C6 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C6')\n",
    "plot_numerical('C6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('C7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C7 after data relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = relax_data(train, test, 'C7')\n",
    "plot_numerical('C7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariate shift after data relaxation:', covariate_shift('C7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical('C14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id_31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Covariate shift:', covariate_shift('id_31'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
